{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43484d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import PyPDF2\n",
    "\n",
    "\n",
    "def tokenize_stem(series):\n",
    "\n",
    "    tokenizer =TreebankWordTokenizer()\n",
    "    stemmer = PorterStemmer()\n",
    "    series = series.apply(lambda x: x.replace(\"\\n\", ' '))\n",
    "    series = series.apply(lambda x: tokenizer.tokenize(x))\n",
    "    series = series.apply(lambda x: [stemmer.stem(w) for w in x])\n",
    "    series = series.apply(lambda x: ' '.join(x))\n",
    "    return series\n",
    "\n",
    "def display_topics(model, feature_names, no_top_words, topic_names=None):\n",
    "    '''\n",
    "    displays topics and returns list of toppics\n",
    "    '''\n",
    "\n",
    "    topic_list = []\n",
    "    for i, topic in enumerate(model.components_):\n",
    "        if not topic_names or not topic_names[i]:\n",
    "            print(\"\\nTopic \", i)\n",
    "        else:\n",
    "            print(\"\\nTopic: '\",topic_names[i],\"'\")\n",
    "\n",
    "        print(\", \".join([feature_names[k]\n",
    "                       for k in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "        topic_list.append(\", \".join([feature_names[k]\n",
    "                       for k in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "    return model.components_, topic_list\n",
    "\n",
    "def return_topics(series, num_topics, no_top_words, model, vectorizer):\n",
    "    '''\n",
    "    returns document_topic matrix and topic modeling model\n",
    "    '''\n",
    "    #turn job into series\n",
    "    series = tokenize_stem(series)\n",
    "    #transform series into corpus\n",
    "    ex_label = [e[:30]+\"...\" for e in series]\n",
    "    #set vectorizer ngrams = (2,2)\n",
    "    vec = vectorizer(stop_words = 'english')\n",
    "\n",
    "    doc_word = vec.fit_transform(series)\n",
    "\n",
    "    #build model\n",
    "    def_model = model(num_topics)\n",
    "    def_model = def_model.fit(doc_word)\n",
    "    doc_topic = def_model.transform(doc_word)\n",
    "    #print('model components: ', def_model.components_[0].shape)\n",
    "    #print('doc_topic', doc_topic[0])\n",
    "    model_components, topic_list = display_topics(def_model, vec.get_feature_names(), no_top_words)\n",
    "    return def_model.components_, doc_topic, def_model, vec, topic_list#, topics\n",
    "\n",
    "\n",
    "def process_data():\n",
    "    '''\n",
    "    uses the functions above to read in files, model, and return a topic_document dataframe\n",
    "    '''\n",
    "    #read in jobs file and get descriptions\n",
    "    df = pd.read_csv('jobs.csv')\n",
    "    #df = df[df.keyword!='marketing']\n",
    "    jobs_df = pd.DataFrame(zip(df['Job Description'], df['keyword']), columns = ['Description', 'Job'])\n",
    "\n",
    "    array, doc, topic_model, vec, topic_list  = return_topics(jobs_df['Description'],20, 10, TruncatedSVD, TfidfVectorizer)\n",
    "\n",
    "    topic_df = pd.DataFrame(doc)\n",
    "    topic_df.columns = ['Topic ' + str(i+1) for i in range(len(topic_df.columns)) ]\n",
    "\n",
    "    topic_df['job'] = jobs_df.Job\n",
    "    #Topic_DF.to_csv('topic_df.csv')\n",
    "    return topic_df, topic_model, vec, topic_list\n",
    "\n",
    "def predictive_modeling(df):\n",
    "    '''\n",
    "    fits, optimizes, and predicts job class based on topic modeling corpus\n",
    "    '''\n",
    "    X,y = df.iloc[:,0:-1], df.iloc[:, -1]\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X,y)\n",
    "\n",
    "    param_grid = {'n_estimators': [100,300, 400, 500, 600], 'max_depth': [3,7,9, 11]}\n",
    "    # search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)\n",
    "    # search.fit(X_tr, y_tr)\n",
    "    # bp = search.best_params_\n",
    "    # print(bp)\n",
    "    #rfc = RandomForestClassifier(n_estimators = bp['n_estimators'], max_depth = bp['max_depth'])\n",
    "    rfc = RandomForestClassifier(n_estimators = 500, max_depth = 9)\n",
    "    rfc.fit(X_tr, y_tr)\n",
    "    print('acc: ', np.mean(cross_val_score(rfc, X_tr, y_tr, scoring = 'accuracy', cv=5)))\n",
    "    print('test_acc: ', accuracy_score(y_te, rfc.predict(X_te)))\n",
    "    print(rfc.predict(X_te))\n",
    "    return rfc\n",
    "\n",
    "def predict_resume(topic_model, model, resume):\n",
    "    '''\n",
    "    transforms a resume based on the topic modeling model and return prediction probabilities per each job class\n",
    "    '''\n",
    "    doc = topic_model.transform(resume)\n",
    "    return model.predict_proba(doc), model.classes_\n",
    "\n",
    "def get_topic_classification_models():\n",
    "    jobs_df, model, vec , topic_list= process_data()\n",
    "    model_1 = predictive_modeling(jobs_df)\n",
    "    return model, model_1, vec\n",
    "\n",
    "# topic_model, classifier, vec= get_topic_classification_models()\n",
    "# topic_model_name = 'topic_model.sav'\n",
    "# classifier_name = 'classification_model.sav'\n",
    "# vec_name = 'job_vec.sav'\n",
    "# pickle.dump(topic_model, open(topic_model_name, 'wb'))\n",
    "# pickle.dump(classifier, open(classifier_name, 'wb'))\n",
    "# pickle.dump(vec, open(vec_name, 'wb'))\n",
    "\n",
    "def main(resume, topic_model, predictor, vec):\n",
    "    '''\n",
    "    run code that predicts resume\n",
    "    '''\n",
    "    #jobs_df, model, vec , topic_list= process_data()\n",
    "    #model_1 = predictive_modeling(jobs_df)\n",
    "\n",
    "    doc = tokenize_stem(resume)\n",
    "    doc = vec.transform(doc)\n",
    "    probabilities, classes = predict_resume(topic_model, predictor, doc)\n",
    "    return classes, probabilities[0]*100\n",
    "\n",
    "#main()\n",
    "#we tried out SVD and NMF, Count Vec and TFIDIF - best combo is SVD and TFIDF\n",
    "\n",
    "# look at topics and see what makes sense\n",
    "\n",
    "# recommend roles that are best for you based on supervised learnings\n",
    "\n",
    "# these are the jobs descriptions that are best for you based on your resume\n",
    "\n",
    "# these are the best words for your resume based on which job you want to go into\n",
    "\n",
    "\n",
    "# NEXT STEPS:\n",
    "# Now we have to fit resumes according to the topic modeling model -\n",
    "    #we my want to add a new function in here to fit the resumes and test out the product\n",
    "\n",
    "    #then we have to turn the model into a streamlit app\n",
    "\n",
    "    #last we want to make the app pretty and have users test it / upload it to the internet for real\n",
    "\n",
    "    #make presentation\n",
    "\n",
    "# Also have to create app and return the\n",
    "\n",
    "#get chart of top toppics from topic modeling\n",
    "pdf_file = open('Project/CV_Neha.pdf', 'rb')\n",
    "read_pdf = PyPDF2.PdfFileReader(pdf_file)\n",
    "page = read_pdf.getPage(0)\n",
    "resume = page.extractText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b0fe2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
